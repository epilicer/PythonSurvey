{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wordcloud example for a PDF file retrieved from Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "urllink = 'http://www.ysk.gov.tr/doc/karar/dosya/78053/2019-4219.pdf'\n",
    "url = urlopen(urllink)\n",
    "filename = urllink.split('/')[-1]\n",
    "filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert PDF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "\n",
    "def convert_pdf_to_txt(path, pages=None):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "    output = StringIO()\n",
    "    manager = PDFResourceManager()\n",
    "    converter = TextConverter(manager, output, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(manager, converter)\n",
    "\n",
    "    infile = open(path, 'rb')\n",
    "    for page in PDFPage.get_pages(infile, pagenums):\n",
    "        interpreter.process_page(page)\n",
    "    infile.close()\n",
    "    converter.close()\n",
    "    text = output.getvalue()\n",
    "    output.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = convert_pdf_to_txt(filename)\n",
    "#text = convert_pdf_to_txt(filename, pages=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "text = text.replace('\\n','')                                                  # remove \\n\n",
    "text = text.replace('T C  YÜKSEK SEÇİM KURULU         Karar No   4219', '')   # remove headings\n",
    "text = text.replace('K A R A R','')\n",
    "text = re.sub(r'\\d+', r'', str(text))                                         # remove digits\n",
    "text = text.replace('\\x0c', '')                                               # replace special-chars\n",
    "text = re.sub(r' +', r' ', str(text))                                         # remove dublicate spaces\n",
    "text = text.strip()                                                           # strip leading/trailing spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define wordcloud function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def drawWordCloud(data, color = 'black'):\n",
    "    corpus =' '.join(data)\n",
    "    wordcloud = WordCloud(background_color=color,\n",
    "                          max_words=100, width=2000, height=1500\n",
    "                         ).generate_from_text(corpus)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.title(filename, fontsize=22)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a corpus and plot wordcloud for all words in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "corpus_with_split = text.split(' ')\n",
    "stopwords_list = set(stopwords.words('turkish'))\n",
    "filtered_words = [word for word in corpus_with_split if word not in stopwords_list]\n",
    "print(filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a corpus by using TurkishStemmer and plot wordcloud for all words in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TurkishStemmer import TurkishStemmer\n",
    "\n",
    "# function to find root of individual words\n",
    "def TurkishStemmerAnalysis(data):\n",
    "    stemmer = TurkishStemmer()\n",
    "    return [stemmer.stem(t) for t in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawWordCloud(TurkishStemmerAnalysis(filtered_words),'white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a corpus by using snowballstemmer and plot wordcloud for all words in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowballstemmer import stemmer\n",
    "\n",
    "# function to find root of individual words\n",
    "def SnowballStemmerAnalysis(data):\n",
    "    findRoot = stemmer('turkish')\n",
    "    return findRoot.stemWords(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawWordCloudText(SnowballStemmerAnalysis(filtered_words), 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a corpus by using Zemberek and plot wordcloud for all words & adjectives  in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype\n",
    "javaPath = r'C:\\Program Files\\Java\\jdk1.8.0_212\\jre\\bin\\server\\jvm.dll'\n",
    "classPath = r'D:\\data-science\\zemberek\\zemberek-tum-2.0.jar'\n",
    "jpype.startJVM(javaPath, '-ea', '-Djava.class.path=%s' % classPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find root of individual words\n",
    "def ZemberekAnalysis(data):\n",
    "    Tr = jpype.JClass(\"net.zemberek.tr.yapi.TurkiyeTurkcesi\")  # load TurkiyeTurkcesi class\n",
    "    tr = Tr()                                                  # initiate tr object\n",
    "    Zemberek = jpype.JClass(\"net.zemberek.erisim.Zemberek\")    # load Zemberek class\n",
    "    zemberek = Zemberek(tr)                                    # initiate zemberek object\n",
    "    words=[]; adjcs=[]; nouns=[]\n",
    "    verbs=[]; specs=[]; abbrs=[]\n",
    "    for t in data:\n",
    "        ans = zemberek.kelimeCozumle(t)\n",
    "        if ans:\n",
    "            root = str(ans[0].kok()).split()[0]\n",
    "            tipo = str(ans[0].kok()).split()[1]\n",
    "            words.append(root)\n",
    "            if tipo == 'SIFAT': adjcs.append(root)\n",
    "            if tipo == 'ISIM': nouns.append(root)\n",
    "            if tipo == 'FIIL': verbs.append(root)\n",
    "            if tipo == 'OZEL': specs.append(t)\n",
    "            if tipo == 'KISALTMA' and len(t) > 1: abbrs.append(t) \n",
    "    else:\n",
    "        pass\n",
    "    return words, adjcs, nouns, verbs, specs, abbrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allwords, adjectives, nouns, verbs, specials, abbreviations = ZemberekAnalysis(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def corpa(data, max_freq=1):\n",
    "    stopwords_list = set(stopwords.words('turkish'))\n",
    "    words = [word for word in data if word not in stopwords_list]\n",
    "    dict_data = {}\n",
    "    for key,value in dict(Counter(words)).items():\n",
    "        if value > max_freq: dict_data[key] = int(value)\n",
    "    return dict_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawWordCloudFreq(data, max_freq=1, color='black', title=''):\n",
    "    dict_corpa = corpa(data, max_freq)\n",
    "    wordcloud = WordCloud(background_color=color,\n",
    "                          max_words=100, width=2000, height=1500\n",
    "                         ).generate_from_frequencies(dict_corpa)\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.title('T.C. YÜKSEK SEÇİM KURULU - Karar No:4219 - {}'.format(title), fontsize=22)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drawWordCloudFreq(specials, 2, color='white', title='Pronouns Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawWordCloudFreq(abbreviations, 1, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawWordCloudFreq(adjectives, 2, color='black', title='Adjectives Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawWordCloudFreq(nouns, 2, color='red', title='Nouns Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drawWordCloudFreq(allwords, 2, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jpype.shutdownJVM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
